{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed0c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Computer Vision\\ship-detector\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import timm\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ruamel.yaml as yaml\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from ship_detector.scripts.prepare_data import rle_decode, tile_geotiff, process_masks, create_synthetic_test\n",
    "from ship_detector.scripts.train_vit import ShipPatchDataset, ViTShipClassifier, get_augmentation_transforms, create_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20e5762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/vit.yaml\"\n",
    "manifest_path = \"data/airbus-ship-detection/train_ship_segmentations_v2.csv\"\n",
    "\n",
    "output_dir = \"outputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "233fe7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "with open(config_path, 'rb') as f:\n",
    "    config = yaml.YAML(typ='rt').load(f)\n",
    "pl.seed_everything(config['data']['random_seed'])\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5d9a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, val_loader = create_data_loader(manifest_path, config)\n",
    "df_mani = pd.read_csv(manifest_path)\n",
    "df_mani['has_ship'] = df_mani['EncodedPixels'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "df_mani['patch_path'] = df_mani['ImageId'].apply(lambda x: f\"data/airbus-ship-detection/train_v2/{x}\")\n",
    "train_df, val_df = train_test_split(\n",
    "    df_mani,\n",
    "    test_size=config['data']['val_split'],\n",
    "    random_state=config['data']['random_seed'],\n",
    "    stratify=df_mani['has_ship']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18838818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((231723, 4), (185378, 4), (46345, 4))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mani.shape, train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d2987c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>patch_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/00003e153.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/0001124c7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "      <td>1</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/000155de5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/000194a2d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/000194a2d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231718</th>\n",
       "      <td>fffedbb6b.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/fffedbb6b.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231719</th>\n",
       "      <td>ffff2aa57.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/ffff2aa57.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231720</th>\n",
       "      <td>ffff6e525.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/ffff6e525.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231721</th>\n",
       "      <td>ffffc50b4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/ffffc50b4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231722</th>\n",
       "      <td>ffffe97f3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>data/airbus-ship-detection/train_v2/ffffe97f3.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231723 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ImageId                                      EncodedPixels  \\\n",
       "0       00003e153.jpg                                                NaN   \n",
       "1       0001124c7.jpg                                                NaN   \n",
       "2       000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...   \n",
       "3       000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...   \n",
       "4       000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...   \n",
       "...               ...                                                ...   \n",
       "231718  fffedbb6b.jpg                                                NaN   \n",
       "231719  ffff2aa57.jpg                                                NaN   \n",
       "231720  ffff6e525.jpg                                                NaN   \n",
       "231721  ffffc50b4.jpg                                                NaN   \n",
       "231722  ffffe97f3.jpg                                                NaN   \n",
       "\n",
       "        has_ship                                         patch_path  \n",
       "0              0  data/airbus-ship-detection/train_v2/00003e153.jpg  \n",
       "1              0  data/airbus-ship-detection/train_v2/0001124c7.jpg  \n",
       "2              1  data/airbus-ship-detection/train_v2/000155de5.jpg  \n",
       "3              1  data/airbus-ship-detection/train_v2/000194a2d.jpg  \n",
       "4              1  data/airbus-ship-detection/train_v2/000194a2d.jpg  \n",
       "...          ...                                                ...  \n",
       "231718         0  data/airbus-ship-detection/train_v2/fffedbb6b.jpg  \n",
       "231719         0  data/airbus-ship-detection/train_v2/ffff2aa57.jpg  \n",
       "231720         0  data/airbus-ship-detection/train_v2/ffff6e525.jpg  \n",
       "231721         0  data/airbus-ship-detection/train_v2/ffffc50b4.jpg  \n",
       "231722         0  data/airbus-ship-detection/train_v2/ffffe97f3.jpg  \n",
       "\n",
       "[231723 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c730b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transform\n",
    "aug_config = config['augmentation']\n",
    "\n",
    "train_transforms = [\n",
    "    transforms.RandomHorizontalFlip(p=aug_config.get('hflip_prob', 0.5)),\n",
    "    transforms.RandomVerticalFlip(p=aug_config.get('vflip_prob', 0.5)),\n",
    "]\n",
    "\n",
    "if aug_config.get('rotation', False):\n",
    "    train_transforms.append(transforms.RandomRotation(degrees=90))\n",
    "\n",
    "if aug_config.get('color_jitter', False):\n",
    "    train_transforms.append(\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.2,\n",
    "            contrast=0.2,\n",
    "            saturation=0.2,\n",
    "            hue=0.1\n",
    "        )\n",
    "    )\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_transforms.extend([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# train_transforms, val_transforms = transforms.Compose(train_transforms), transforms.Compose(val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd6187c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'name': 'vit_base_patch16_224', 'pretrained': True, 'freeze_backbone_epochs': 3, 'download': False, 'local_weights_path': 'model_states', 'preprocessing_method': 'adaptive'}, 'training': {'batch_size': 128, 'max_epochs': 40, 'early_stopping_patience': 7, 'pos_weight': 4.0, 'use_weighted_sampler': True, 'precision': 16, 'small_ship_focus': True, 'mixup_alpha': 0.2}, 'optimizer': {'name': 'adamw', 'lr': 8e-05, 'weight_decay': 0.02}, 'scheduler': {'name': 'cosine', 'T_max': 30, 'eta_min': 1e-07, 'warmup_epochs': 5}, 'augmentation': {'hflip_prob': 0.5, 'vflip_prob': 0.5, 'rotation': True, 'color_jitter': True, 'gaussian_blur_prob': 0.1, 'brightness_range': [0.8, 1.2], 'contrast_range': [0.9, 1.1], 'ship_aware_crop': True, 'preserv_small_objects': True}, 'data': {'val_split': 0.2, 'num_workers': 4, 'random_seed': 42, 'target_size': 224, 'interpolation': 'area', 'apply_sharpening': True, 'sharpening_strength': 0.3, 'min_ship_pixel_ratio': 0.001, 'max_background_ratio': 0.95}, 'evaluation': {'use_sliding_window': True, 'ensemble_predictions': True, 'confidence_threshold': 0.4}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41348c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ShipPatchDataset(config=config, manifest_df=train_df, transform=train_transforms, is_training=True)\n",
    "val_dataset = ShipPatchDataset(config=config, manifest_df=val_df, transform=val_transforms, is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f456759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling imbalance class with weighted sampling\n",
    "if config['training'].get('use_weighted_sampler', False):\n",
    "    train_labels = train_df['has_ship'].values\n",
    "    class_counts = np.bincount(train_labels)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    sample_weights = class_weights[train_labels]\n",
    "    \n",
    "    sampler =WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(train_dataset),\n",
    "        replacement=True\n",
    "    )\n",
    "    shuffle = False\n",
    "else:\n",
    "    sampler = None\n",
    "    shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be4312fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=shuffle,\n",
    "    sampler=sampler,\n",
    "    num_workers=config['data']['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['data']['num_workers'],\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bcb271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ViTShipClassifier(config)\n",
    "# torch.save(model.state_dict(), f'model_states/pretrained/vit_base_patch16_224.pth')\n",
    "config['model']['pretrained'] = False\n",
    "model = ViTShipClassifier(config)\n",
    "if config['model']['pretrained'] == False:\n",
    "    state_dict = torch.load(f\"model_states/pretrained/{config['model']['name']}.pth\", map_location='cpu')\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469697c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_checkpoint = \"outputs/checkpoints/vit-epoch=04-val_acc=0.962.ckpt\"\n",
    "# checkpoint = torch.load(vit_checkpoint, map_location='cpu', weights_only=False)\n",
    "# model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "62a7be86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTShipClassifier(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26ee17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=os.path.join(output_dir, 'checkpoints'),\n",
    "        filename='vit-{epoch:02d}-{val_acc:.3f}',\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_top_k=3,\n",
    "        save_last=True,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=config['training']['early_stopping_patience'],\n",
    "        mode='min'\n",
    "    ),\n",
    "    LearningRateMonitor(logging_interval='epoch')\n",
    "]\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=output_dir,\n",
    "    name='vit_logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef5f88bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Computer Vision\\ship-detector\\.venv\\Lib\\site-packages\\lightning_fabric\\connector.py:571: UserWarning:\n",
      "\n",
      "`precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=config['training']['max_epochs'],\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    log_every_n_steps=10,\n",
    "    deterministic=True,\n",
    "    precision=config['training'].get('precision', 32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de120b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader, ckpt_path=vit_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c16bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ship-detector (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
